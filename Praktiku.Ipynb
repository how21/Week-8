{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum week 8 Web Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama  : Andi rafi fajar wally\n",
    "\n",
    "NIM   : 162112133097\n",
    "\n",
    "Matkul: Algoritma Pemograman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDengan menggunakan Python Requests dan BeautifulSoup cobalah untuk scraping 1 halaman website unair news (https://unair.ac.id/news) dan judul berita yang ada hari ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data telah disimpan dalam berita.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Masukkan URL yang dituju\n",
    "url = \"https://unair.ac.id/news\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    all_titles = []\n",
    "    # Mengambil semua yang termasuk h1, h2, h3, h4, h5, h6\n",
    "    for tag in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        title = tag.get_text().strip()\n",
    "        if title:  # Pastikan tidak ada teks kosong\n",
    "            all_titles.append(title)\n",
    "\n",
    "    if all_titles:\n",
    "        # Membuat DataFrame dari semua judul berita\n",
    "        df = pd.DataFrame({'Headline Berita': all_titles})\n",
    "\n",
    "        # Menyimpan DataFrame ke dalam file CSV\n",
    "        df.to_csv('Nomor 1.csv', index=False)\n",
    "\n",
    "        print(\"Data telah disimpan dalam berita.csv\")\n",
    "    else:\n",
    "        print(\"Tidak ada judul berita di halaman ini.\")\n",
    "else:\n",
    "    print(\"Gagal mengambil halaman web.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline Berita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr Andriyanto, Alumnus UNAIR yang Dilantik Men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERITA TERKINI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Websvaganza 2023 Hadirkan Bazar Kosmetik untuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pentingnya Mengenal Potensi Diri Melalui Pemah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dukung Pendidikan Merata UNAIR Berikan Beasisw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apa Sih UKM Wanala ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFOGRAFIK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KATA PAKAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ancam Boikot SpaceX, Dosen UNAIR Sebut Israel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr Andriyanto, Alumnus UNAIR yang Dilantik Men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KAMPUS MERDEKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kisah Mahasiswa UNAIR Eksplor Kanada Melalui I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Perjalanan Menantang Mahasiswa UNAIR Ikuti IIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRESTASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gagas Platform Digital Kepenulisan Ilmiah, Mah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sajikan Ide Pengisian Energi Hybrid, Mahasiswa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>INOVASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tim PKM-RE UNAIR Ciptakan Terapi untuk Penderi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tim PKM-RE UNAIR Ciptakan Formula untuk Tingka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tim PKM-RE FPK UNAIR Ciptakan Produk Penghamba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BERITA FOTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Foto: Kunjungan MWA Universitas Pendidikan Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Foto : UNAIR Berikan Beasiswa Siswa Sekolah Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Foto : Universitas Airlangga Gelar Pameran Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ARTIKEL ILMIAH POPULER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Konversi Gas Karbon Dioksida Menjadi Asam Aset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Meningkatkan Kemampuan CZTS sebagai Bahan Sel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Efektivitas dan Tantangan Pengajaran Online da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BERITA FAKULTAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Accounting Fair I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DULINAN : Peduli Anak Jalanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Menarik ! Mahasiswa Perlu Belajar tentang Big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MAHASISWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kafilah UNAIR Siap Memulai Perjalanan ke MTQ N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BEM UNAIR Laksanakan Aksi Peduli Bumi Lewat Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ALUMNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>IKA UNAIR Gandeng Pemkab Gresik Bantu Turunkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Alumnus UNAIR Gandeng Masyarakat Lokal Kembang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dulu Wisudawan Berprestasi, Kini Raih Beasiswa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BERITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tim Scientia UNAIR Gapai Juara 2 Call For Pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BEM FST dan Rawatungga Gelar Kolaborasi Webina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Infografik: Profil Guru Besar Prof. Dian Yulie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Kesiapan Rumah Sakit Rujukan COVID-19 Dalam Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Analisis Genom Mitokondria pada Clarias cameru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Analisis Pengetahuan Tentang Kelainan Mulut Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rilis: Gubes UNAIR Ungkap Potensi Smart Breedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Apakah Indonesia Negara Agraris dengan Indeks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MARI TERHUBUNG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Headline Berita\n",
       "0   Dr Andriyanto, Alumnus UNAIR yang Dilantik Men...\n",
       "1                                      BERITA TERKINI\n",
       "2   Websvaganza 2023 Hadirkan Bazar Kosmetik untuk...\n",
       "3   Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...\n",
       "4   Pentingnya Mengenal Potensi Diri Melalui Pemah...\n",
       "5   Dukung Pendidikan Merata UNAIR Berikan Beasisw...\n",
       "6                                Apa Sih UKM Wanala ?\n",
       "7                                          INFOGRAFIK\n",
       "8                                          KATA PAKAR\n",
       "9   Ancam Boikot SpaceX, Dosen UNAIR Sebut Israel ...\n",
       "10  Dr Andriyanto, Alumnus UNAIR yang Dilantik Men...\n",
       "11                                     KAMPUS MERDEKA\n",
       "12  Kisah Mahasiswa UNAIR Eksplor Kanada Melalui I...\n",
       "13  Perjalanan Menantang Mahasiswa UNAIR Ikuti IIS...\n",
       "14                                           PRESTASI\n",
       "15  Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...\n",
       "16  Gagas Platform Digital Kepenulisan Ilmiah, Mah...\n",
       "17  Sajikan Ide Pengisian Energi Hybrid, Mahasiswa...\n",
       "18                                            INOVASI\n",
       "19  Tim PKM-RE UNAIR Ciptakan Terapi untuk Penderi...\n",
       "20  Tim PKM-RE UNAIR Ciptakan Formula untuk Tingka...\n",
       "21  Tim PKM-RE FPK UNAIR Ciptakan Produk Penghamba...\n",
       "22                                        BERITA FOTO\n",
       "23  Foto: Kunjungan MWA Universitas Pendidikan Ind...\n",
       "24  Foto : UNAIR Berikan Beasiswa Siswa Sekolah Da...\n",
       "25  Foto : Universitas Airlangga Gelar Pameran Pen...\n",
       "26                             ARTIKEL ILMIAH POPULER\n",
       "27  Konversi Gas Karbon Dioksida Menjadi Asam Aset...\n",
       "28  Meningkatkan Kemampuan CZTS sebagai Bahan Sel ...\n",
       "29  Efektivitas dan Tantangan Pengajaran Online da...\n",
       "30                                    BERITA FAKULTAS\n",
       "31                                  Accounting Fair I\n",
       "32                      DULINAN : Peduli Anak Jalanan\n",
       "33  Menarik ! Mahasiswa Perlu Belajar tentang Big ...\n",
       "34                                          MAHASISWA\n",
       "35  Mahasiswa UNAIR Sabet Juara 1 Kategori Lomba I...\n",
       "36  Kafilah UNAIR Siap Memulai Perjalanan ke MTQ N...\n",
       "37  BEM UNAIR Laksanakan Aksi Peduli Bumi Lewat Pr...\n",
       "38                                             ALUMNI\n",
       "39  IKA UNAIR Gandeng Pemkab Gresik Bantu Turunkan...\n",
       "40  Alumnus UNAIR Gandeng Masyarakat Lokal Kembang...\n",
       "41  Dulu Wisudawan Berprestasi, Kini Raih Beasiswa...\n",
       "42                                             BERITA\n",
       "43  Tim Scientia UNAIR Gapai Juara 2 Call For Pape...\n",
       "44  BEM FST dan Rawatungga Gelar Kolaborasi Webina...\n",
       "45  Infografik: Profil Guru Besar Prof. Dian Yulie...\n",
       "46  Kesiapan Rumah Sakit Rujukan COVID-19 Dalam Me...\n",
       "47  Analisis Genom Mitokondria pada Clarias cameru...\n",
       "48  Analisis Pengetahuan Tentang Kelainan Mulut Be...\n",
       "49  Rilis: Gubes UNAIR Ungkap Potensi Smart Breedi...\n",
       "50  Apakah Indonesia Negara Agraris dengan Indeks ...\n",
       "51                                     MARI TERHUBUNG"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil semua tagline dari halaman utama unair news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berita Terbaru : Websvaganza 2023 Hadirkan Bazar Kosmetik untuk Dorong Kepercayaan Diri dan Hilangkan Insecure\n"
     ]
    }
   ],
   "source": [
    "url = \"https://unair.ac.id/news\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    today_news = soup.find('h2', class_='elementor-post__title')\n",
    "\n",
    "    if today_news:\n",
    "        today_news_title = today_news.text.strip()\n",
    "        print(\"Berita Terbaru :\", today_news_title)\n",
    "    else:\n",
    "        print(\"Tidak ada judul berita hari ini.\")\n",
    "else:\n",
    "    print(\"Gagal mengambil halaman web.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini kurang lebih sama dengan yang pertama tapi ini lebih spesifik karena saya menentukan class nya yaitu elementor-post__title, dan disini hanya mengambil element paling atas alias berita paling terbaru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lalu, lakukan crawling unair news dengan mengkombinasikan Python Request, beautifulsoup, dan for loop, untuk mengambil judul berita dari kategori featured news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Halaman                                     Berita Terkini\n",
      "0         1  Dr Andriyanto, Alumnus UNAIR yang Dilantik Men...\n",
      "1         1  UNAIR Raih 4,5 Trees Rating pada UI GreenMetri...\n",
      "2         1  Pakar Politik UNAIR Sebut Pengusungan Gibran J...\n",
      "3         1  Berkomitmen Tingkatkan Transparansi Informasi,...\n",
      "4         1  Komitmen Tingkatkan Kualitas Pendidikan, Rekto...\n",
      "5         1  Tambah Lagi, UNAIR Kini Miliki 11 Jurnal Ilmia...\n",
      "6         1  UNAIR Raih Anugerah Jatim Bangkit Awards Berka...\n",
      "7         1  Kukuhkan Tujuh Guru Besar, Rektor UNAIR Ajak A...\n",
      "8         1  Beri Kuliah Tamu di UNAIR, Mahfud MD Tekankan ...\n",
      "9         1  UNAIR Anugerahi Khofifah Gelar Doktor Honoris ...\n",
      "10        1  UNAIR Luluskan 1.382 Wisudawan, Rektor: Anda O...\n",
      "11        1  Rektor Beri Pesan Gubes untuk Bumikan Ilmu Pen...\n",
      "12        2  UNAIR Bagikan 1974 Sertifikat Halal Gratis unt...\n",
      "13        2  Kukuhkan Tujuh Guru Besar, Rektor UNAIR Tekank...\n",
      "14        2  UNAIR Tingkatkan Kontribusi dengan Tambah 7 Gu...\n",
      "15        2  UNAIR Duduki Peringkat Kedua Nasional Versi TH...\n",
      "16        2  Dukung Merdeka Belajar, UNAIR Berikan Ruang Ek...\n",
      "17        2  Pengukuhan Gubes Wujudkan UNAIR Jadi SMART Uni...\n",
      "18        2  Jadi Tuan Rumah The 6th ASEAN+3 Rector’s Confe...\n",
      "19        2  Intip Kisah Guru Besar UNAIR yang 18 Tahun Men...\n",
      "20        2  Kukuhkan Gubes, Rektor: Semoga Target Segera T...\n",
      "21        2  Singkirkan Puluhan Peserta, Mahasiswa UNAIR Ba...\n",
      "22        2  Jadi Pionir, FKH UNAIR Adakan Program MBKM di ...\n",
      "23        2          Resmi! UNAIR Bakal Miliki Plaza Airlangga\n",
      "24        3  Menkes Luncurkan Permenkes Rumah Sakit Kapal, ...\n",
      "25        3  Pengukuhan Guru Besar Jadi Tambahan Energi bag...\n",
      "26        3  Kukuhkan Empat Guru Besar FK, Rektor UNAIR Tek...\n",
      "27        3  Masuk Deretan Top 100 Peneliti Indonesia, Waki...\n",
      "28        3  UNAIR Siap Tingkatkan Kontribusi dengan 12 Gur...\n",
      "29        3  UNAIR Sambut Kedatangan 390 Peserta Pertukaran...\n",
      "30        3  Janis Rosalita, Alumnus UNAIR jadi Atlet Terba...\n",
      "31        3  Rektor UNAIR Beri Tanggapan Kebijakan Baru Pen...\n",
      "32        3  IKA UNAIR Wilayah Inggris Gelar Silaturahmi da...\n",
      "33        3  Produk Penurun Glukosa dalam Darah Gubes UNAIR...\n",
      "34        3  Mahasiswa UNAIR Ciptakan Alat Deteksi Stress p...\n",
      "35        3  Tanam Jahe dan Sereh untuk Tingkatkan Kesehata...\n",
      "36        4  Dosen FISIP UNAIR Tanggapi Putusan MK yang Men...\n",
      "37        4  Kolaborasi UNAIR dan UTM Tingkatkan Ekowisata ...\n",
      "38        4  Sambut Tahun Politik, UNAIR Tandatangani Dekla...\n",
      "39        4  Bagi-bagi Sepeda Hingga Musisi Meriahkan Amert...\n",
      "40        4  Puncak PKKMB UNAIR, Rektor dan Gubernur Khofif...\n",
      "41        4  Tim Mahasiswa UNAIR Borong 4 Medali dalam Ajan...\n",
      "42        4  UNAIR Bersama Wali Kota Surabaya Resmikan Thea...\n",
      "43        4  Western Sydney University Kunjungi UNAIR Bahas...\n",
      "44        4  Sejumlah Tokoh Dikukuhkan Jadi Maba UNAIR, dar...\n",
      "45        4  UNAIR Gandeng UTM Malaysia Beri Akses Pendidik...\n",
      "46        4  Guru Besar FKM UNAIR Raih Penghargaan Penggera...\n",
      "47        4  Rayakan Kemerdekaan RI, Kali Pertama UNAIR Buk...\n",
      "48        5  Pakaian Adat hingga Launching Logo Dies Natali...\n",
      "49        5  Perjuangan dan Pengabdian di Pulau Sabu: Misi ...\n",
      "50        5  6 Mahasiswa MSU Malaysia Raih Gelar Double Deg...\n",
      "51        5  Luluskan 866 Wisudawan, Rektor: Lulusan Harus ...\n",
      "52        5  FKM UNAIR Dapat Apresiasi dari Wali Kota Surab...\n",
      "53        5  Usung Revitalisasi Makanan Tradisional, Mahasi...\n",
      "54        5  UNAIR Kokohkan Relasi Internasional Melalui Pe...\n",
      "55        5  Mahasiswa FIB UNAIR Raih Juara I Creative Vide...\n",
      "56        5  Cerita Sasha Maba FK UNAIR yang Sempat Gagal 1...\n",
      "57        5  Tim UNAIR Sabet Juara III Lomba Debat Action P...\n",
      "58        5    Excellence Rank, UNAIR Peringkat 2 di Indonesia\n",
      "59        5  Menjangkau Titik 0 Selatan Indonesia hingga Pu...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL awal\n",
    "base_url = \"https://unair.ac.id/category/featured/\"\n",
    "\n",
    "# List untuk menyimpan judul berita dari semua halaman\n",
    "all_news_data = []\n",
    "\n",
    "for page in range(1, 6):  # jumlah halaman yang ingin Anda crawl\n",
    "    # Membentuk URL untuk halaman tertentu\n",
    "    url = f\"{base_url}page/{page}/\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        h2_elements = soup.find_all('h3', class_='elementor-post__title')\n",
    "\n",
    "        if h2_elements:\n",
    "            news_data = []\n",
    "            for h2 in h2_elements:\n",
    "                news_title = \" \".join(h2.stripped_strings)\n",
    "                news_data.append({'Halaman': page, 'Berita Terkini': news_title})\n",
    "\n",
    "            all_news_data.extend(news_data)\n",
    "        else:\n",
    "            print(f\"Tidak ada judul berita di halaman {page}.\")\n",
    "    else:\n",
    "        print(f\"Gagal mengambil halaman web {page}.\")\n",
    "\n",
    "# Membuat DataFrame dari semua data berita\n",
    "df = pd.DataFrame(all_news_data)\n",
    "\n",
    "# Menampilkan DataFrame sebagai tabel\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kode diatas melakukan crawling terhadap 5 page awal pada halaman featured news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Nomor 2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tSetelah itu, gunakan scrapy untuk melakukan crawling website https://bit.ly/scrapingtry dan menyimpan judul game beserta harganya dalam tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (21.3)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (6.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (2.0.7)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (23.3.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (23.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (63.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: Twisted<23.8.0,>=18.9.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (0.8.0)\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (4.9.3)\n",
      "Requirement already satisfied: tldextract in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (5.0.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (41.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.5.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (1.0.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->scrapy) (3.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (3.12.4)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kece\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan install package scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengimport Libray Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'store', using template directory 'C:\\Users\\Kece\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    D:\\Perkuliahan\\KULIAH\\semester_5\\Alpro\\Week 8\\store\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd store\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat Folder project dengan package scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'store_spider' using template 'basic' in module:\n",
      "  store.spiders.store_spider\n"
     ]
    }
   ],
   "source": [
    "!cd store/store/spiders && scrapy genspider store_spider store.playstation.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat file store_spider didalam folder spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting D:/Perkuliahan/Kuliah/semester_5/Alpro/Week_8/store/store/spiders/store_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile D:/Perkuliahan/Kuliah/semester_5/Alpro/Week_8/store/store/spiders/store_spider.py\n",
    "import scrapy\n",
    "\n",
    "class store(scrapy.Spider):\n",
    "    # Nama spider yang digunakan saat menjalankannya dengan perintah 'scrapy crawl'\n",
    "    name = 'scrapy_Store'\n",
    "    \n",
    "    # URL yang akan di-crawl\n",
    "    start_urls = ['https://store.playstation.com/en-id/category/05a2d027-cedc-4ac0-abeb-8fc26fec7180/']\n",
    "\n",
    "    # Fungsi 'parse' yang akan dipanggil untuk mengolah respons dari halaman web\n",
    "    def parse(self, response):\n",
    "        # Menggunakan CSS Selectors untuk mengekstrak judul game dan harga\n",
    "        judul = response.css('span.psw-t-body.psw-c-t-1.psw-t-truncate-2.psw-m-b-2::text').getall()\n",
    "        harga = response.css('span.psw-m-r-3::text').getall()\n",
    "\n",
    "        # Menggabungkan judul dan harga dengan menggunakan zip()\n",
    "        for judul, harga in zip(judul, harga):\n",
    "            # Menghasilkan item (dalam hal ini, judul game dan harga)\n",
    "            yield {\n",
    "                'Title': judul.strip(),  # Menyimpan judul game dengan menghilangkan spasi di awal dan akhir\n",
    "                'Harga': harga.strip()  # Menyimpan harga dengan menghilangkan spasi di awal dan akhir\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "playstation = pd.read_csv(\"D:/Perkuliahan/Kuliah/semester_5/Alpro/Week_8/store/scrape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Harga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rogue Legacy 2 (Simplified Chinese, English, K...</td>\n",
       "      <td>Rp 349,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inscryption (Simplified Chinese, English, Kore...</td>\n",
       "      <td>Rp 279,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deus Ex: Mankind Divided (Game)</td>\n",
       "      <td>Rp 102,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Killing Floor 2 (Simplified Chinese, English, ...</td>\n",
       "      <td>Rp 429,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lonely Mountains: Downhill (Simplified Chinese...</td>\n",
       "      <td>Rp 279,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ratchet &amp; Clank: Rift Apart (Simplified Chines...</td>\n",
       "      <td>Rp 1,029,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Horizon Forbidden West™ (Simplified Chinese, E...</td>\n",
       "      <td>Rp 579,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Horizon Forbidden West™ (Simplified Chinese, E...</td>\n",
       "      <td>Rp 729,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hundred Days - Winemaking Simulator (Simplifie...</td>\n",
       "      <td>Rp 429,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carto (Simplified Chinese, English, Korean, Ja...</td>\n",
       "      <td>Rp 279,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dodgeball Academia (Simplified Chinese, Englis...</td>\n",
       "      <td>Rp 349,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Wild at Heart (Simplified Chinese, English...</td>\n",
       "      <td>Rp 349,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thief (Game)</td>\n",
       "      <td>Rp 52,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MX vs ATV Legends (Simplified Chinese, English...</td>\n",
       "      <td>Rp 318,450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HUMANITY (English, Japanese)</td>\n",
       "      <td>Rp 429,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Watch Dogs: Legion PS4 &amp; PS5 (Simplified Chine...</td>\n",
       "      <td>Rp 749,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Watch Dogs: Legion PS4 &amp; PS5 (Simplified Chine...</td>\n",
       "      <td>Rp 112,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UNCHARTED: Legacy of Thieves Collection (Simpl...</td>\n",
       "      <td>Rp 729,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ELEX II PS4 &amp; PS5 (Simplified Chinese, English...</td>\n",
       "      <td>Rp 373,050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Conan Exiles (Simplified Chinese, English, Kor...</td>\n",
       "      <td>Rp 699,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kena: Bridge of Spirits PS4 &amp; PS5 (Simplified ...</td>\n",
       "      <td>Rp 579,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dishonored 2 (English/Chinese Ver.)</td>\n",
       "      <td>Rp 85,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TOMB RAIDER DEFINITIVE EDITION full game (Engl...</td>\n",
       "      <td>Rp 74,750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DOOM Eternal Standard Edition (Simplified Chin...</td>\n",
       "      <td>Rp 532,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title         Harga\n",
       "0   Rogue Legacy 2 (Simplified Chinese, English, K...    Rp 349,000\n",
       "1   Inscryption (Simplified Chinese, English, Kore...    Rp 279,000\n",
       "2                     Deus Ex: Mankind Divided (Game)    Rp 102,000\n",
       "3   Killing Floor 2 (Simplified Chinese, English, ...    Rp 429,000\n",
       "4   Lonely Mountains: Downhill (Simplified Chinese...    Rp 279,000\n",
       "5   Ratchet & Clank: Rift Apart (Simplified Chines...  Rp 1,029,000\n",
       "6   Horizon Forbidden West™ (Simplified Chinese, E...    Rp 579,000\n",
       "7   Horizon Forbidden West™ (Simplified Chinese, E...    Rp 729,000\n",
       "8   Hundred Days - Winemaking Simulator (Simplifie...    Rp 429,000\n",
       "9   Carto (Simplified Chinese, English, Korean, Ja...    Rp 279,000\n",
       "10  Dodgeball Academia (Simplified Chinese, Englis...    Rp 349,000\n",
       "11  The Wild at Heart (Simplified Chinese, English...    Rp 349,000\n",
       "12                                       Thief (Game)     Rp 52,350\n",
       "13  MX vs ATV Legends (Simplified Chinese, English...    Rp 318,450\n",
       "14                       HUMANITY (English, Japanese)    Rp 429,000\n",
       "15  Watch Dogs: Legion PS4 & PS5 (Simplified Chine...    Rp 749,000\n",
       "16  Watch Dogs: Legion PS4 & PS5 (Simplified Chine...    Rp 112,350\n",
       "17  UNCHARTED: Legacy of Thieves Collection (Simpl...    Rp 729,000\n",
       "18  ELEX II PS4 & PS5 (Simplified Chinese, English...    Rp 373,050\n",
       "19  Conan Exiles (Simplified Chinese, English, Kor...    Rp 699,000\n",
       "20  Kena: Bridge of Spirits PS4 & PS5 (Simplified ...    Rp 579,000\n",
       "21                Dishonored 2 (English/Chinese Ver.)     Rp 85,800\n",
       "22  TOMB RAIDER DEFINITIVE EDITION full game (Engl...     Rp 74,750\n",
       "23  DOOM Eternal Standard Edition (Simplified Chin...    Rp 532,000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playstation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut hasil crawling dari website playstation yang telah disimpan pada csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
